{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/XescLlabres/tfgFLM/blob/main/HUSE_per_masstum/rforestMASSTUMORALS.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O38ekpymciBF"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pEojIUT_cxGU"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('df_sense_nan.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JLgswB3sea87",
        "outputId": "986fae37-cd75-4d82-8fea-82f473f07920"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Columna: ID, Tipus: category\n",
            "Columna: GENDER, Tipus: category\n",
            "Columna: AGE_AT_TACE, Tipus: int64\n",
            "Columna: DAYS_PRETACE, Tipus: int64\n",
            "Columna: MAX_TM_DIAM, Tipus: float64\n",
            "Columna: 7-11_CRITERIA, Tipus: float64\n",
            "Columna: 7-11_CAT, Tipus: category\n",
            "Columna: Weigh, Tipus: float64\n",
            "Columna: heigh, Tipus: float64\n",
            "Columna: BMI, Tipus: float64\n",
            "Columna: BMI_category, Tipus: category\n",
            "Columna: HCV, Tipus: category\n",
            "Columna: Alcohol abuse, Tipus: category\n",
            "Columna: Obesity, Tipus: category\n",
            "Columna: Adquired and Inhereted disorders, Tipus: category\n",
            "Columna: Aflatoxin, Tipus: category\n",
            "Columna: Drug-abuse/addict, Tipus: category\n",
            "Columna: Smoke, Tipus: category\n",
            "Columna: no_active_ex, Tipus: category\n",
            "Columna: Diabetes, Tipus: category\n",
            "Columna: Hypertension, Tipus: category\n",
            "Columna: Cancer History, Tipus: category\n",
            "Columna: Active_cancer, Tipus: category\n",
            "Columna: B-block treatment, Tipus: category\n",
            "Columna: Statin treatment, Tipus: category\n",
            "Columna: Antiretroviral treatment, Tipus: category\n",
            "Columna: Cronic Kidney Insufficiency, Tipus: category\n",
            "Columna: Kidney substitute treatment, Tipus: category\n",
            "Columna: Fibrosis grade, Tipus: category\n",
            "Columna: TN0M0, Tipus: category\n",
            "Columna: ALBI Score, Tipus: float64\n",
            "Columna: ALBI grade, Tipus: category\n",
            "Columna: Child Pugh, Tipus: category\n",
            "Columna: BCLC, Tipus: category\n",
            "Columna: Meld Original, Tipus: float64\n",
            "Columna: MELD Original SCORE, Tipus: category\n",
            "Columna: Meld-Na, Tipus: float64\n",
            "Columna: Glóbulos blancos, Tipus: float64\n",
            "Columna: Glóbulos rojos, Tipus: float64\n",
            "Columna: Hemoglobin (mg/dl), Tipus: float64\n",
            "Columna: Hematocrito (%), Tipus: float64\n",
            "Columna: Plaquetas, Tipus: float64\n",
            "Columna: Neutrófilos, Tipus: float64\n",
            "Columna: Eosinófilos, Tipus: float64\n",
            "Columna: Basófilos, Tipus: float64\n",
            "Columna: Monocitos, Tipus: float64\n",
            "Columna: Linfocitos, Tipus: float64\n",
            "Columna: Ratio neutrófilos/linfocitos (NLR), Tipus: float64\n",
            "Columna: INR, Tipus: float64\n",
            "Columna: Quick (%), Tipus: float64\n",
            "Columna: Sodio, Tipus: float64\n",
            "Columna: Potasio, Tipus: float64\n",
            "Columna: Albumine g/L, Tipus: float64\n",
            "Columna: Total Bilirrubine mg/dL, Tipus: float64\n",
            "Columna: Fosfatasa alcalina, Tipus: float64\n",
            "Columna: GGT, Tipus: float64\n",
            "Columna: ALT, Tipus: float64\n",
            "Columna: AST, Tipus: float64\n",
            "Columna: Glucosa, Tipus: float64\n",
            "Columna: Urea, Tipus: float64\n",
            "Columna: Creatinine mg/dL, Tipus: float64\n",
            "Columna: Alpha fetoprotein, Tipus: float64\n",
            "Columna: Alpha fetoprotein category, Tipus: category\n",
            "Columna: HCV Serology, Tipus: category\n",
            "Columna: otherserology positivie result, Tipus: category\n",
            "Columna: Overall Tumor distribution, Tipus: category\n",
            "Columna: Observation modality, Tipus: category\n",
            "Columna: N_OBS, Tipus: category\n",
            "Columna: Location Observation 1, Tipus: category\n",
            "Columna: LI-RADS, Tipus: category\n",
            "Columna: Size 2D mm, Tipus: int64\n",
            "Columna: Size 2D mm.1, Tipus: float64\n",
            "Columna: LR M criteria, Tipus: category\n",
            "Columna: LR-M_describe, Tipus: category\n",
            "Columna: NonRimAPHE, Tipus: category\n",
            "Columna: NPWO, Tipus: category\n",
            "Columna: EC, Tipus: category\n",
            "Columna: Margins, Tipus: category\n",
            "Columna: LRMAggregate, Tipus: category\n",
            "Columna: Viable, Tipus: category\n"
          ]
        }
      ],
      "source": [
        "# Identifica columnes amb menys de 20 valors únics\n",
        "columnes_categoriques = [col for col in df.columns if df[col].nunique() < 10]\n",
        "columnes_categoriques.append('Location Observation 1')\n",
        "columnes_categoriques.append('ID')\n",
        "columnes_categoriques.remove('Meld Original')\n",
        "\n",
        "\n",
        "# Converteix aquestes columnes a categòriques\n",
        "for col in columnes_categoriques:\n",
        "    df[col] = df[col].astype('category')\n",
        "\n",
        "# Identifica la resta de columnes (no categòriques)\n",
        "columnes_numeriques = [col for col in df.columns if col not in columnes_categoriques]\n",
        "\n",
        "# Converteix columnes numèriques de format amb comes a numèrics\n",
        "for col in columnes_numeriques:\n",
        "    # Substitueix comes per punts (només funciona per columnes tipus object o text)\n",
        "    df[col] = df[col].astype(str).str.replace(',', '.')\n",
        "    # Converteix a numèric\n",
        "    df[col] = pd.to_numeric(df[col], errors='coerce')  # Valors no vàlids es converteixen a NaN\n",
        "\n",
        "for columna in df.columns:\n",
        "    print(f\"Columna: {columna}, Tipus: {df[columna].dtype}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tDJlj6Bve_D9",
        "outputId": "202a92f9-f85f-4d82-be13-87069a15003c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Columnes numèriques: Index(['AGE_AT_TACE', 'DAYS_PRETACE', 'MAX_TM_DIAM', '7-11_CRITERIA', 'Weigh',\n",
            "       'heigh', 'BMI', 'ALBI Score', 'Meld Original', 'Meld-Na',\n",
            "       'Glóbulos blancos', 'Glóbulos rojos', 'Hemoglobin (mg/dl)',\n",
            "       'Hematocrito (%)', 'Plaquetas', 'Neutrófilos', 'Eosinófilos',\n",
            "       'Basófilos', 'Monocitos', 'Linfocitos',\n",
            "       'Ratio neutrófilos/linfocitos (NLR)', 'INR', 'Quick (%)', 'Sodio',\n",
            "       'Potasio', 'Albumine g/L', 'Total Bilirrubine mg/dL',\n",
            "       'Fosfatasa alcalina', 'GGT', 'ALT', 'AST', 'Glucosa', 'Urea',\n",
            "       'Creatinine mg/dL', 'Alpha fetoprotein', 'Size 2D mm', 'Size 2D mm.1'],\n",
            "      dtype='object')\n",
            "      ID GENDER  AGE_AT_TACE  DAYS_PRETACE  MAX_TM_DIAM  7-11_CRITERIA  \\\n",
            "0  222.0      1     1.712184     -0.468331     1.352758       0.222472   \n",
            "1  346.0      1     0.598105     -0.781814    -1.119573      -1.352067   \n",
            "2  613.0      0    -1.731332     -0.050353    -0.078591      -0.136633   \n",
            "3  613.2      0    -1.731332     -0.050353    -0.078591      -0.136633   \n",
            "4  697.0      0     1.205785      0.472119    -0.859327      -1.186326   \n",
            "\n",
            "  7-11_CAT     Weigh     heigh       BMI  ... Size 2D mm Size 2D mm.1  \\\n",
            "0        1 -1.149129 -2.732923  0.125083  ...   1.284056     1.435192   \n",
            "1        0 -1.760237 -2.054237 -1.032224  ...  -0.808822    -0.923144   \n",
            "2        0 -1.081228  0.253296 -1.241375  ...   0.138896    -0.061444   \n",
            "3        0 -1.081228  0.253296 -1.241375  ...  -0.769333    -0.787086   \n",
            "4        0 -0.877526 -1.104076 -0.416720  ...  -0.413939    -0.787086   \n",
            "\n",
            "  LR M criteria LR-M_describe NonRimAPHE NPWO   EC Margins LRMAggregate Viable  \n",
            "0           0.0           0.0        1.0  1.0  1.0     0.0          0.0    0.0  \n",
            "1           0.0           0.0        1.0  1.0  0.0     0.0          0.0    0.0  \n",
            "2           0.0           0.0        1.0  1.0  1.0     1.0          0.0    1.0  \n",
            "3           0.0           0.0        1.0  1.0  0.0     0.0          0.0    1.0  \n",
            "4           0.0           0.0        1.0  1.0  0.0     0.0          0.0    1.0  \n",
            "\n",
            "[5 rows x 80 columns]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "# Identificar les columnes numèriques\n",
        "numerical_columns = df.select_dtypes(include=['float64', 'int64']).columns\n",
        "print(\"Columnes numèriques:\", numerical_columns)\n",
        "df['7-11_CAT'] = df['7-11_CAT'].map({'LOW': 0, 'INTERMEDIATE': 1, 'HIGH': 2})\n",
        "# Inicialitzar el StandardScaler\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Aplicar el scaler només a les columnes numèriques\n",
        "df[numerical_columns] = scaler.fit_transform(df[numerical_columns])\n",
        "\n",
        "# Comprova els resultats\n",
        "print(df.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2G3Gv2F9fTot"
      },
      "outputs": [],
      "source": [
        "from sklearn.utils import resample\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import LeaveOneOut\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "\n",
        "y = df.loc[:, \"Viable\"].values\n",
        "\n",
        "\n",
        "X = df.loc[:, (df.columns != \"Viable\") & (df.columns != \"ID\")].values\n",
        "feature_names = df.columns[(df.columns != \"Viable\") & (df.columns != \"ID\")]\n",
        "\n",
        "loo = LeaveOneOut()\n",
        "#Hiperparàmetres calculats amb un grid_search per a resultats òptims\n",
        "model = RandomForestClassifier(\n",
        "    n_estimators=100,  # Nombre d'arbres\n",
        "    max_depth= None,\n",
        "    min_samples_leaf=4,\n",
        "    min_samples_split=10,\n",
        "    random_state=42,   # Per resultats consistents\n",
        "    class_weight= None  # Manejar classes desequilibrades\n",
        ")\n",
        "\n",
        "total_bootstrap_iterations = 100\n",
        "variable_counts = np.zeros(X.shape[1])\n",
        "\n",
        "all_bootstrap_probabilities = []\n",
        "\n",
        "for train_index, test_index in loo.split(X):\n",
        "    X_train, X_test = X[train_index], X[test_index]\n",
        "    y_train, y_test = y[train_index], y[test_index]\n",
        "\n",
        "\n",
        "    bootstrapped_probabilities = []\n",
        "\n",
        "    for _ in range(total_bootstrap_iterations):\n",
        "        X_train_bootstrap, y_train_bootstrap = resample(X_train, y_train, replace=True)\n",
        "\n",
        "        model.fit(X_train_bootstrap, y_train_bootstrap)\n",
        "\n",
        "        prob = model.predict_proba(X_test)[:, 1][0]\n",
        "        bootstrapped_probabilities.append(prob)\n",
        "\n",
        "\n",
        "    all_bootstrap_probabilities.append(bootstrapped_probabilities)\n",
        "\n",
        "df_probabilities = pd.DataFrame(all_bootstrap_probabilities)\n",
        "df_probabilities.to_csv('df_probabilities.csv', index=False)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iRwjez16gG2R"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score, accuracy_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WX8jnISviTtW"
      },
      "outputs": [],
      "source": [
        "taula1 = pd.read_csv('df_probabilities.csv')\n",
        "taula2 = pd.read_csv('df_sense_nan.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J9YdVuWEikWu",
        "outputId": "001b20c9-5a64-459a-d5e5-37f8039fe81a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      ID  Viable  y_true\n",
            "0  222.0       0     0.0\n",
            "1  346.0       1     0.0\n",
            "2  613.0       1     1.0\n",
            "3  613.2       1     1.0\n",
            "4  697.0       1     1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-55-5575d5fdf319>:22: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  taula2_processed.rename(columns={'Viable': 'y_true'}, inplace=True)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "id_column = taula2.iloc[:, 0]\n",
        "\n",
        "probabilities = taula1.iloc[:, 1:]\n",
        "\n",
        "y_pred = (probabilities.mean(axis=1) >= 0.5).astype(int)\n",
        "\n",
        "taula1_processed = pd.DataFrame({'ID': id_column, 'Viable': y_pred})\n",
        "\n",
        "\n",
        "taula2_processed = taula2[['ID', 'Viable']]\n",
        "taula2_processed.rename(columns={'Viable': 'y_true'}, inplace=True)\n",
        "\n",
        "taula05 = pd.merge(taula1_processed, taula2_processed, on='ID')\n",
        "\n",
        "print(taula05.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "65ga8nTFiwq1",
        "outputId": "4ad6a615-bf9e-483b-efab-fbce4db4cf0b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Matriz de Confusión:\n",
            "[[57 39]\n",
            " [26 81]]\n",
            "Precisión: 0.68\n",
            "Recall: 0.76\n",
            "F1-Score: 0.71\n",
            "Exactitud: 0.68\n"
          ]
        }
      ],
      "source": [
        "y_pred = taula05['Viable']\n",
        "y_true = taula05['y_true']\n",
        "\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "print(\"Matriu de confusió:\")\n",
        "print(cm)\n",
        "\n",
        "precision = precision_score(y_true, y_pred)\n",
        "print(f\"Precisió: {precision:.2f}\")\n",
        "\n",
        "recall = recall_score(y_true, y_pred)\n",
        "print(f\"Recall: {recall:.2f}\")\n",
        "\n",
        "f1 = f1_score(y_true, y_pred)\n",
        "print(f\"F1-Score: {f1:.2f}\")\n",
        "\n",
        "accuracy = accuracy_score(y_true, y_pred)\n",
        "print(f\"Exactitud: {accuracy:.2f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nqogh_hOizzj",
        "outputId": "22c3aad1-04bc-4184-fc7a-ced15c1ee7a4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tabla final creada y guardada en 'final_table.csv'.\n"
          ]
        }
      ],
      "source": [
        "df_data = pd.read_csv(\"df_sense_nan.csv\")\n",
        "\n",
        "df_probabilities = pd.read_csv(\"df_probabilities.csv\")\n",
        "\n",
        "df_data_subset = df_data[['ID', 'Viable']]\n",
        "\n",
        "if len(df_data_subset) == len(df_probabilities):\n",
        "    df_final = pd.concat([df_data_subset, df_probabilities], axis=1)\n",
        "\n",
        "    df_final.to_csv(\"final_table.csv\", index=False)\n",
        "\n",
        "    print(\"Tabla final creada y guardada en 'final_table.csv'.\")\n",
        "else:\n",
        "    print(\"Error: Los DataFrames tienen diferente número de filas. Verifica tus datos.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k5TjLpWX76AL"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('final_table.csv')\n",
        "\n",
        "id_column = 'ID'\n",
        "diagnosis_column = 'Viable'\n",
        "prob_columns = df.columns[3:]\n",
        "\n",
        "def calcular_intervalo(probabilidades, li, ls):\n",
        "    lower_bound = np.percentile(probabilidades, li)\n",
        "    upper_bound = np.percentile(probabilidades, ls)\n",
        "    return lower_bound, upper_bound"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MfxsWsgr7826"
      },
      "outputs": [],
      "source": [
        "intervalos_confianza = []\n",
        "\n",
        "for index, row in df.iterrows():\n",
        "    probabilidades = row[prob_columns].values  # Extraer las probabilidades\n",
        "    lower, upper = calcular_intervalo(probabilidades, 2.5, 97.5)\n",
        "    intervalos_confianza.append([row[id_column], row[diagnosis_column], lower, upper])\n",
        "\n",
        "# Crear un nuevo DataFrame con los intervalos de confianza\n",
        "df_intervalos = pd.DataFrame(intervalos_confianza, columns=[id_column, diagnosis_column, 'lower_bound', 'upper_bound'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GHw1wZXw8CmI"
      },
      "outputs": [],
      "source": [
        "def calcular_TP(a, b):\n",
        "    TP = min(1 - a, b)\n",
        "    return TP\n",
        "def calcular_AP(a,b):\n",
        "    AP = min(a, 1-b)\n",
        "    return AP\n",
        "def calcular_EP(a,b):\n",
        "    EP = (b-a)\n",
        "    return EP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w4eYYitB8FDR"
      },
      "outputs": [],
      "source": [
        "# Añadir la columna TP aplicando la función calcular_TP a lower_bound y upper_bound\n",
        "df_intervalos['TP'] = df_intervalos.apply(lambda row: calcular_TP(row['lower_bound'], row['upper_bound']), axis=1)\n",
        "\n",
        "# Añadir la columna AP aplicando la función calcular_AP a lower_bound y upper_bound\n",
        "df_intervalos['AP'] = df_intervalos.apply(lambda row: calcular_AP(row['lower_bound'], row['upper_bound']), axis=1)\n",
        "\n",
        "# Añadir la columna EP aplicando la función calcular_EP a lower_bound y upper_bound\n",
        "df_intervalos['EP'] = df_intervalos.apply(lambda row: calcular_EP(row['lower_bound'], row['upper_bound']), axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YvPkiKyL8G9O",
        "outputId": "fbe81154-aa07-4a7a-d197-bc671c571488"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Medias:\n",
            "TP    0.577986\n",
            "AP    0.193733\n",
            "EP    0.384253\n",
            "dtype: float64\n"
          ]
        }
      ],
      "source": [
        "# Calcular medias de TP, AP y EP\n",
        "medias = df_intervalos[['TP', 'AP', 'EP']].mean()\n",
        "print(\"Medias:\")\n",
        "print(medias)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOjUPSLUnEViK7kRy3ag+7N",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}