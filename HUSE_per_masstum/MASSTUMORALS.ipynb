{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOdKM7e4NoBX6/s+WSRCRUl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/XescLlabres/tfgFLM/blob/main/HUSE_per_masstum/MASSTUMORALS.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O38ekpymciBF"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('df_sense_nan.csv')"
      ],
      "metadata": {
        "id": "pEojIUT_cxGU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Identifica columnes amb menys de 20 valors únics\n",
        "columnes_categoriques = [col for col in df.columns if df[col].nunique() < 10]\n",
        "columnes_categoriques.append('Location Observation 1')\n",
        "columnes_categoriques.append('ID')\n",
        "columnes_categoriques.remove('Meld Original')\n",
        "\n",
        "\n",
        "# Converteix aquestes columnes a categòriques\n",
        "for col in columnes_categoriques:\n",
        "    df[col] = df[col].astype('category')\n",
        "\n",
        "# Identifica la resta de columnes (no categòriques)\n",
        "columnes_numeriques = [col for col in df.columns if col not in columnes_categoriques]\n",
        "\n",
        "# Converteix columnes numèriques de format amb comes a numèrics\n",
        "for col in columnes_numeriques:\n",
        "    # Substitueix comes per punts (només funciona per columnes tipus object o text)\n",
        "    df[col] = df[col].astype(str).str.replace(',', '.')\n",
        "    # Converteix a numèric\n",
        "    df[col] = pd.to_numeric(df[col], errors='coerce')  # Valors no vàlids es converteixen a NaN\n",
        "\n",
        "for columna in df.columns:\n",
        "    print(f\"Columna: {columna}, Tipus: {df[columna].dtype}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JLgswB3sea87",
        "outputId": "4cf860c7-7f99-44ea-f6f2-08112cb04c3e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Columna: ID, Tipus: category\n",
            "Columna: GENDER, Tipus: category\n",
            "Columna: AGE_AT_TACE, Tipus: int64\n",
            "Columna: DAYS_PRETACE, Tipus: int64\n",
            "Columna: MAX_TM_DIAM, Tipus: float64\n",
            "Columna: 7-11_CRITERIA, Tipus: float64\n",
            "Columna: 7-11_CAT, Tipus: category\n",
            "Columna: Weigh, Tipus: float64\n",
            "Columna: heigh, Tipus: float64\n",
            "Columna: BMI, Tipus: float64\n",
            "Columna: BMI_category, Tipus: category\n",
            "Columna: HCV, Tipus: category\n",
            "Columna: Alcohol abuse, Tipus: category\n",
            "Columna: Obesity, Tipus: category\n",
            "Columna: Adquired and Inhereted disorders, Tipus: category\n",
            "Columna: Aflatoxin, Tipus: category\n",
            "Columna: Drug-abuse/addict, Tipus: category\n",
            "Columna: Smoke, Tipus: category\n",
            "Columna: no_active_ex, Tipus: category\n",
            "Columna: Diabetes, Tipus: category\n",
            "Columna: Hypertension, Tipus: category\n",
            "Columna: Cancer History, Tipus: category\n",
            "Columna: Active_cancer, Tipus: category\n",
            "Columna: B-block treatment, Tipus: category\n",
            "Columna: Statin treatment, Tipus: category\n",
            "Columna: Antiretroviral treatment, Tipus: category\n",
            "Columna: Cronic Kidney Insufficiency, Tipus: category\n",
            "Columna: Kidney substitute treatment, Tipus: category\n",
            "Columna: Fibrosis grade, Tipus: category\n",
            "Columna: TN0M0, Tipus: category\n",
            "Columna: ALBI Score, Tipus: float64\n",
            "Columna: ALBI grade, Tipus: category\n",
            "Columna: Child Pugh, Tipus: category\n",
            "Columna: BCLC, Tipus: category\n",
            "Columna: Meld Original, Tipus: float64\n",
            "Columna: MELD Original SCORE, Tipus: category\n",
            "Columna: Meld-Na, Tipus: float64\n",
            "Columna: Glóbulos blancos, Tipus: float64\n",
            "Columna: Glóbulos rojos, Tipus: float64\n",
            "Columna: Hemoglobin (mg/dl), Tipus: float64\n",
            "Columna: Hematocrito (%), Tipus: float64\n",
            "Columna: Plaquetas, Tipus: float64\n",
            "Columna: Neutrófilos, Tipus: float64\n",
            "Columna: Eosinófilos, Tipus: float64\n",
            "Columna: Basófilos, Tipus: float64\n",
            "Columna: Monocitos, Tipus: float64\n",
            "Columna: Linfocitos, Tipus: float64\n",
            "Columna: Ratio neutrófilos/linfocitos (NLR), Tipus: float64\n",
            "Columna: INR, Tipus: float64\n",
            "Columna: Quick (%), Tipus: float64\n",
            "Columna: Sodio, Tipus: float64\n",
            "Columna: Potasio, Tipus: float64\n",
            "Columna: Albumine g/L, Tipus: float64\n",
            "Columna: Total Bilirrubine mg/dL, Tipus: float64\n",
            "Columna: Fosfatasa alcalina, Tipus: float64\n",
            "Columna: GGT, Tipus: float64\n",
            "Columna: ALT, Tipus: float64\n",
            "Columna: AST, Tipus: float64\n",
            "Columna: Glucosa, Tipus: float64\n",
            "Columna: Urea, Tipus: float64\n",
            "Columna: Creatinine mg/dL, Tipus: float64\n",
            "Columna: Alpha fetoprotein, Tipus: float64\n",
            "Columna: Alpha fetoprotein category, Tipus: category\n",
            "Columna: HCV Serology, Tipus: category\n",
            "Columna: otherserology positivie result, Tipus: category\n",
            "Columna: Overall Tumor distribution, Tipus: category\n",
            "Columna: Observation modality, Tipus: category\n",
            "Columna: N_OBS, Tipus: category\n",
            "Columna: Location Observation 1, Tipus: category\n",
            "Columna: LI-RADS, Tipus: category\n",
            "Columna: Size 2D mm, Tipus: int64\n",
            "Columna: Size 2D mm.1, Tipus: float64\n",
            "Columna: LR M criteria, Tipus: category\n",
            "Columna: LR-M_describe, Tipus: category\n",
            "Columna: NonRimAPHE, Tipus: category\n",
            "Columna: NPWO, Tipus: category\n",
            "Columna: EC, Tipus: category\n",
            "Columna: Margins, Tipus: category\n",
            "Columna: LRMAggregate, Tipus: category\n",
            "Columna: Viable, Tipus: category\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "# Identificar les columnes numèriques\n",
        "numerical_columns = df.select_dtypes(include=['float64', 'int64']).columns\n",
        "print(\"Columnes numèriques:\", numerical_columns)\n",
        "df['7-11_CAT'] = df['7-11_CAT'].map({'LOW': 0, 'INTERMEDIATE': 1, 'HIGH': 2})\n",
        "# Inicialitzar el StandardScaler\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Aplicar el scaler només a les columnes numèriques\n",
        "df[numerical_columns] = scaler.fit_transform(df[numerical_columns])\n",
        "\n",
        "# Comprova els resultats\n",
        "print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tDJlj6Bve_D9",
        "outputId": "25f08a9f-5c9d-4b5f-b098-f42ae7410054"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Columnes numèriques: Index(['AGE_AT_TACE', 'DAYS_PRETACE', 'MAX_TM_DIAM', '7-11_CRITERIA', 'Weigh',\n",
            "       'heigh', 'BMI', 'ALBI Score', 'Meld Original', 'Meld-Na',\n",
            "       'Glóbulos blancos', 'Glóbulos rojos', 'Hemoglobin (mg/dl)',\n",
            "       'Hematocrito (%)', 'Plaquetas', 'Neutrófilos', 'Eosinófilos',\n",
            "       'Basófilos', 'Monocitos', 'Linfocitos',\n",
            "       'Ratio neutrófilos/linfocitos (NLR)', 'INR', 'Quick (%)', 'Sodio',\n",
            "       'Potasio', 'Albumine g/L', 'Total Bilirrubine mg/dL',\n",
            "       'Fosfatasa alcalina', 'GGT', 'ALT', 'AST', 'Glucosa', 'Urea',\n",
            "       'Creatinine mg/dL', 'Alpha fetoprotein', 'Size 2D mm', 'Size 2D mm.1'],\n",
            "      dtype='object')\n",
            "      ID GENDER  AGE_AT_TACE  DAYS_PRETACE  MAX_TM_DIAM  7-11_CRITERIA  \\\n",
            "0  222.0      1     1.712184     -0.468331     1.352758       0.222472   \n",
            "1  346.0      1     0.598105     -0.781814    -1.119573      -1.352067   \n",
            "2  613.0      0    -1.731332     -0.050353    -0.078591      -0.136633   \n",
            "3  613.2      0    -1.731332     -0.050353    -0.078591      -0.136633   \n",
            "4  697.0      0     1.205785      0.472119    -0.859327      -1.186326   \n",
            "\n",
            "  7-11_CAT     Weigh     heigh       BMI  ... Size 2D mm Size 2D mm.1  \\\n",
            "0        1 -1.149129 -2.732923  0.125083  ...   1.284056     1.435192   \n",
            "1        0 -1.760237 -2.054237 -1.032224  ...  -0.808822    -0.923144   \n",
            "2        0 -1.081228  0.253296 -1.241375  ...   0.138896    -0.061444   \n",
            "3        0 -1.081228  0.253296 -1.241375  ...  -0.769333    -0.787086   \n",
            "4        0 -0.877526 -1.104076 -0.416720  ...  -0.413939    -0.787086   \n",
            "\n",
            "  LR M criteria LR-M_describe NonRimAPHE NPWO   EC Margins LRMAggregate Viable  \n",
            "0           0.0           0.0        1.0  1.0  1.0     0.0          0.0    0.0  \n",
            "1           0.0           0.0        1.0  1.0  0.0     0.0          0.0    0.0  \n",
            "2           0.0           0.0        1.0  1.0  1.0     1.0          0.0    1.0  \n",
            "3           0.0           0.0        1.0  1.0  0.0     0.0          0.0    1.0  \n",
            "4           0.0           0.0        1.0  1.0  0.0     0.0          0.0    1.0  \n",
            "\n",
            "[5 rows x 80 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "y = df.loc[:, \"Viable\"].values\n",
        "\n",
        "\n",
        "X = df.loc[:, (df.columns != \"Viable\") & (df.columns != \"ID\")].values\n",
        "\n",
        "\n",
        "# Crear el model base amb liblinear\n",
        "model = LogisticRegression(penalty='l1', solver='liblinear', max_iter=1000)\n",
        "\n",
        "# Definir els valors per a la cerca\n",
        "param_grid = {'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000]}\n",
        "\n",
        "# Crear l'objecte GridSearchCV\n",
        "grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=5, scoring='roc_auc', n_jobs=-1)\n",
        "\n",
        "# Ajustar el model\n",
        "grid_search.fit(X, y)\n",
        "\n",
        "# Resultats\n",
        "print(\"Millor valor de C:\", grid_search.best_params_['C'])\n",
        "print(\"Millor puntuació AUC:\", grid_search.best_score_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nGhSRaOCD0Jh",
        "outputId": "33fe7784-4065-4bad-db6a-bc6058e84802"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Millor valor de C: 0.1\n",
            "Millor puntuació AUC: 0.6822055137844611\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.utils import resample\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import LeaveOneOut\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "\n",
        "y = df.loc[:, \"Viable\"].values\n",
        "\n",
        "\n",
        "X = df.loc[:, (df.columns != \"Viable\") & (df.columns != \"ID\")].values\n",
        "feature_names = df.columns[(df.columns != \"Viable\") & (df.columns != \"ID\")]\n",
        "\n",
        "loo = LeaveOneOut()\n",
        "model = LogisticRegression(max_iter=1000, penalty='l1', solver='liblinear', C=0.1)  # LASSO con penalización L1\n",
        "\n",
        "total_bootstrap_iterations = 1000\n",
        "variable_counts = np.zeros(X.shape[1])\n",
        "\n",
        "all_bootstrap_probabilities = []\n",
        "\n",
        "# Aplicar LOOCV con Bootstrap\n",
        "for train_index, test_index in loo.split(X):\n",
        "    X_train, X_test = X[train_index], X[test_index]\n",
        "    y_train, y_test = y[train_index], y[test_index]\n",
        "\n",
        "\n",
        "    bootstrapped_probabilities = []\n",
        "\n",
        "    for _ in range(total_bootstrap_iterations):\n",
        "        X_train_bootstrap, y_train_bootstrap = resample(X_train, y_train, replace=True)\n",
        "\n",
        "        model.fit(X_train_bootstrap, y_train_bootstrap)\n",
        "\n",
        "        prob = model.predict_proba(X_test)[:, 1][0]\n",
        "        bootstrapped_probabilities.append(prob)\n",
        "\n",
        "        # Actualizar el contador amb les variables seleccionades (coef != 0)\n",
        "        variable_counts += model.coef_[0] != 0\n",
        "\n",
        "    all_bootstrap_probabilities.append(bootstrapped_probabilities)\n",
        "\n",
        "df_probabilities = pd.DataFrame(all_bootstrap_probabilities)\n",
        "df_probabilities.to_csv('df_probabilities.csv', index=False)\n",
        "\n",
        "variable_importance = pd.DataFrame({\n",
        "    'Variable': feature_names,\n",
        "    'Frequency (%)': (variable_counts / (total_bootstrap_iterations * loo.get_n_splits(X))) * 100  # Porcentaje de veces seleccionada\n",
        "}).sort_values(by='Frequency (%)', ascending=False)\n",
        "\n",
        "\n",
        "# Mostrar la importancia de les variables\n",
        "df_probabilities.head()\n",
        "pd.set_option('display.max_rows', None)\n",
        "print(\"\\nImportancia de las variables (Count y Frequency):\")\n",
        "print(variable_importance)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2G3Gv2F9fTot",
        "outputId": "7e6bab8f-2096-4777-933c-3cece46bba16"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Importancia de las variables (Count y Frequency):\n",
            "                              Variable  Frequency (%)\n",
            "70                        Size 2D mm.1      94.168159\n",
            "5                             7-11_CAT      89.703483\n",
            "67              Location Observation 1      83.613433\n",
            "50                             Potasio      82.261194\n",
            "71                       LR M criteria      75.329353\n",
            "1                          AGE_AT_TACE      73.469652\n",
            "59                    Creatinine mg/dL      52.886567\n",
            "17                        no_active_ex      49.964179\n",
            "49                               Sodio      42.806965\n",
            "68                             LI-RADS      36.668657\n",
            "43                           Basófilos      35.006965\n",
            "66                               N_OBS      26.362189\n",
            "6                                Weigh      24.896020\n",
            "9                         BMI_category      24.811443\n",
            "56                                 AST      24.327861\n",
            "55                                 ALT      22.759204\n",
            "2                         DAYS_PRETACE      21.078109\n",
            "35                             Meld-Na      16.503483\n",
            "4                        7-11_CRITERIA      15.954726\n",
            "29                          ALBI Score      14.081592\n",
            "8                                  BMI      13.754726\n",
            "33                       Meld Original      12.986070\n",
            "44                           Monocitos      12.776617\n",
            "40                           Plaquetas      12.351244\n",
            "48                           Quick (%)      11.638806\n",
            "47                                 INR      11.525373\n",
            "69                          Size 2D mm      11.515423\n",
            "72                       LR-M_describe      10.897015\n",
            "64          Overall Tumor distribution       9.645274\n",
            "46  Ratio neutrófilos/linfocitos (NLR)       9.407463\n",
            "54                                 GGT       8.619403\n",
            "32                                BCLC       8.415423\n",
            "53                  Fosfatasa alcalina       8.220896\n",
            "36                    Glóbulos blancos       7.845771\n",
            "37                      Glóbulos rojos       7.244279\n",
            "57                             Glucosa       6.736816\n",
            "60                   Alpha fetoprotein       6.191542\n",
            "51                        Albumine g/L       6.100995\n",
            "3                          MAX_TM_DIAM       6.052736\n",
            "39                     Hematocrito (%)       5.770647\n",
            "42                         Eosinófilos       4.900498\n",
            "41                         Neutrófilos       4.566667\n",
            "52             Total Bilirrubine mg/dL       3.945274\n",
            "58                                Urea       3.831841\n",
            "38                  Hemoglobin (mg/dl)       3.691542\n",
            "7                                heigh       3.475124\n",
            "22                   B-block treatment       1.923383\n",
            "28                               TN0M0       1.801990\n",
            "45                          Linfocitos       1.341294\n",
            "65                Observation modality       0.664179\n",
            "75                                  EC       0.490547\n",
            "76                             Margins       0.421393\n",
            "27                      Fibrosis grade       0.373632\n",
            "34                 MELD Original SCORE       0.245771\n",
            "11                       Alcohol abuse       0.183582\n",
            "63      otherserology positivie result       0.167662\n",
            "18                            Diabetes       0.133831\n",
            "16                               Smoke       0.106965\n",
            "30                          ALBI grade       0.087065\n",
            "10                                 HCV       0.057711\n",
            "19                        Hypertension       0.044776\n",
            "62                        HCV Serology       0.035323\n",
            "61          Alpha fetoprotein category       0.033831\n",
            "23                    Statin treatment       0.027363\n",
            "12                             Obesity       0.019900\n",
            "20                      Cancer History       0.014428\n",
            "15                   Drug-abuse/addict       0.006468\n",
            "24            Antiretroviral treatment       0.003980\n",
            "74                                NPWO       0.002488\n",
            "21                       Active_cancer       0.000498\n",
            "73                          NonRimAPHE       0.000000\n",
            "0                               GENDER       0.000000\n",
            "31                          Child Pugh       0.000000\n",
            "26         Kidney substitute treatment       0.000000\n",
            "25         Cronic Kidney Insufficiency       0.000000\n",
            "14                           Aflatoxin       0.000000\n",
            "13    Adquired and Inhereted disorders       0.000000\n",
            "77                        LRMAggregate       0.000000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score, accuracy_score"
      ],
      "metadata": {
        "id": "iRwjez16gG2R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "taula1 = pd.read_csv('df_probabilities.csv')\n",
        "taula2 = pd.read_csv('df_sense_nan.csv')"
      ],
      "metadata": {
        "id": "WX8jnISviTtW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "id_column = taula2.iloc[:, 0]\n",
        "\n",
        "probabilities = taula1.iloc[:, 1:]\n",
        "y_pred = (probabilities.mean(axis=1) >= 0.5).astype(int)\n",
        "\n",
        "taula1_processed = pd.DataFrame({'ID': id_column, 'Viable': y_pred})\n",
        "\n",
        "\n",
        "taula2_processed = taula2[['ID', 'Viable']]\n",
        "taula2_processed.rename(columns={'Viable': 'y_true'}, inplace=True)\n",
        "\n",
        "taula05 = pd.merge(taula1_processed, taula2_processed, on='ID')\n",
        "\n",
        "print(taula05.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J9YdVuWEikWu",
        "outputId": "791827d5-c712-46f0-f88d-b182b145e1a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      ID  Viable  y_true\n",
            "0  222.0       0     0.0\n",
            "1  346.0       1     0.0\n",
            "2  613.0       1     1.0\n",
            "3  613.2       1     1.0\n",
            "4  697.0       1     1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-150-5575d5fdf319>:22: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  taula2_processed.rename(columns={'Viable': 'y_true'}, inplace=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = taula05['Viable']\n",
        "y_true = taula05['y_true']\n",
        "\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "print(\"Matriu de confusió:\")\n",
        "print(cm)\n",
        "\n",
        "precision = precision_score(y_true, y_pred)\n",
        "print(f\"Precisión: {precision:.2f}\")\n",
        "\n",
        "recall = recall_score(y_true, y_pred)\n",
        "print(f\"Recall: {recall:.2f}\")\n",
        "\n",
        "f1 = f1_score(y_true, y_pred)\n",
        "print(f\"F1-Score: {f1:.2f}\")\n",
        "\n",
        "accuracy = accuracy_score(y_true, y_pred)\n",
        "print(f\"Exactitut: {accuracy:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "65ga8nTFiwq1",
        "outputId": "6d84094a-3435-4c3d-e9e0-b516d17cfec3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Matriz de Confusión:\n",
            "[[52 44]\n",
            " [22 85]]\n",
            "Precisión: 0.66\n",
            "Recall: 0.79\n",
            "F1-Score: 0.72\n",
            "Exactitud: 0.67\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_data = pd.read_csv(\"df_sense_nan.csv\")\n",
        "\n",
        "df_probabilities = pd.read_csv(\"df_probabilities.csv\")\n",
        "\n",
        "df_data_subset = df_data[['ID', 'Viable']]\n",
        "\n",
        "if len(df_data_subset) == len(df_probabilities):\n",
        "    df_final = pd.concat([df_data_subset, df_probabilities], axis=1)\n",
        "\n",
        "    df_final.to_csv(\"final_table.csv\", index=False)\n",
        "\n",
        "    print(\"Tabla final creada y guardada en 'final_table.csv'.\")\n",
        "else:\n",
        "    print(\"Error: Los DataFrames tienen diferente número de filas. Verifica tus datos.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nqogh_hOizzj",
        "outputId": "2bb5d687-7cfe-45ad-86f4-6984c86cc242"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tabla final creada y guardada en 'final_table.csv'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('final_table.csv')\n",
        "\n",
        "id_column = 'ID'\n",
        "diagnosis_column = 'Viable'\n",
        "prob_columns = df.columns[3:]\n",
        "\n",
        "def calcular_intervalo(probabilidades, li, ls):\n",
        "    lower_bound = np.percentile(probabilidades, li)\n",
        "    upper_bound = np.percentile(probabilidades, ls)\n",
        "    return lower_bound, upper_bound"
      ],
      "metadata": {
        "id": "k5TjLpWX76AL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "intervalos_confianza = []\n",
        "\n",
        "for index, row in df.iterrows():\n",
        "    probabilidades = row[prob_columns].values\n",
        "    lower, upper = calcular_intervalo(probabilidades, 2.5, 97.5)\n",
        "    intervalos_confianza.append([row[id_column], row[diagnosis_column], lower, upper])\n",
        "\n",
        "df_intervalos = pd.DataFrame(intervalos_confianza, columns=[id_column, diagnosis_column, 'lower_bound', 'upper_bound'])"
      ],
      "metadata": {
        "id": "MfxsWsgr7826"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calcular_TP(a, b):\n",
        "    TP = min(1 - a, b)\n",
        "    return TP\n",
        "def calcular_AP(a,b):\n",
        "    AP = min(a, 1-b)\n",
        "    return AP\n",
        "def calcular_EP(a,b):\n",
        "    EP = (b-a)\n",
        "    return EP"
      ],
      "metadata": {
        "id": "GHw1wZXw8CmI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_intervalos['TP'] = df_intervalos.apply(lambda row: calcular_TP(row['lower_bound'], row['upper_bound']), axis=1)\n",
        "\n",
        "df_intervalos['AP'] = df_intervalos.apply(lambda row: calcular_AP(row['lower_bound'], row['upper_bound']), axis=1)\n",
        "\n",
        "df_intervalos['EP'] = df_intervalos.apply(lambda row: calcular_EP(row['lower_bound'], row['upper_bound']), axis=1)"
      ],
      "metadata": {
        "id": "w4eYYitB8FDR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "medias = df_intervalos[['TP', 'AP', 'EP']].mean()\n",
        "print(\"Medias:\")\n",
        "print(medias)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YvPkiKyL8G9O",
        "outputId": "9bc158f8-e69b-4b2f-f494-11b58123fad3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Medias:\n",
            "TP    0.564444\n",
            "AP    0.235506\n",
            "EP    0.328938\n",
            "dtype: float64\n"
          ]
        }
      ]
    }
  ]
}